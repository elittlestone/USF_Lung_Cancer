Assuming unrestricted shared filesystem usage.
None
host: ethanlittlestone
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
run_scanpy_script        1
total                    1

Select jobs to execute...
Execute 1 jobs...
[Thu Jul 24 09:56:06 2025]
localrule run_scanpy_script:
    input: data/wildtype_h5_files
    output: data/processed/concatenated_anndata.h5ad
    jobid: 0
    reason: Missing output files: data/processed/concatenated_anndata.h5ad
    resources: tmpdir=/var/folders/7x/7dyyb4rs5rj9h5yn26lxbwj40000gn/T
Shell command: 
    python scripts/python_scripts/ALK_positive_single_cell_workflow.py     --h5_directory data/wildtype_h5_files --pre_processed_h5_file data/processed/concatenated_anndata.h5ad
    
[Thu Jul 24 09:56:16 2025]
Finished jobid: 0 (Rule: run_scanpy_script)
1 of 1 steps (100%) done
Complete log(s): /Users/ethanlittlestone/USF_Lung_Cancer/.snakemake/log/2025-07-24T095606.666800.snakemake.log
