Assuming unrestricted shared filesystem usage.
None
host: ethanlittlestone
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
run_scanpy_script        1
total                    1

Select jobs to execute...
Execute 1 jobs...
[Thu Jul 24 11:08:14 2025]
localrule run_scanpy_script:
    input: data/wildtype_h5_files
    output: data/processed/concatenated_anndata.h5ad, results/geo_figures/violin_qc.png, results/geo_figures/scatter_total_counts_vs_per_mito_counts.png, results/geo_figures/scatter_total_counts_vs_gene_counts.png, results/geo_figures/umap_samples_scvi.png, results/geo_figures/umap_leiden_scvi_clusters.png, results/geo_figures/umap_qc_metrics_scvi.png
    jobid: 0
    reason: Forced execution
    resources: tmpdir=/var/folders/7x/7dyyb4rs5rj9h5yn26lxbwj40000gn/T
Shell command: 
    python scripts/python_scripts/ALK_positive_single_cell_workflow.py     --h5_directory data/wildtype_h5_files --pre_processed_h5_file data/processed/concatenated_anndata.h5ad
    
[Thu Jul 24 11:49:45 2025]
Finished jobid: 0 (Rule: run_scanpy_script)
1 of 1 steps (100%) done
Complete log(s): /Users/ethanlittlestone/USF_Lung_Cancer/.snakemake/log/2025-07-24T110814.831689.snakemake.log
